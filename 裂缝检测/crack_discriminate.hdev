<?xml version="1.0" encoding="UTF-8"?>
<hdevelop file_version="1.2" halcon_version="23.05.0.0">
<procedure name="main">
<interface/>
<body>
<c>**明确设置一些配置参数，例如输入</c>
<c>*尺寸和批量大小。</c>
<l>InputImageWidth := 224</l>
<l>InputImageHeight := 224</l>
<l>InputImageDepth := 1</l>
<l>hdl_name:='UNet_3.hdl'</l>
<l>file_exists (hdl_name,FileExists)</l>
<l>if (not(FileExists))</l>
<l>    create_unet_model (InputImageHeight, InputImageWidth, InputImageDepth, hdl_name)</l>
<l>endif</l>
<c>*存放分类图片的上一级路径</c>
<c></c>
<l>RawImageFolder := 'D:/desk/数据集/'</l>
<c>*存放预处理数据的总路径</c>
<l>ExampleDataDir:= RawImageFolder+'class_data'</l>
<c>*存放预处理数据的二级路径</c>
<l>DataDirectoryBaseName := ExampleDataDir + '/dldataset_pokeman'</l>
<c>*图像的基目录。</c>
<l>ImageDir:='D:/desk/数据集/100_images'</l>
<c>*分割图像的基础目录。</c>
<l>SegmentationDir :='D:/desk/数据集/100_labels'</l>
<c>*MVTec深度学习工具创建的DLDataset字典的路径</c>
<l>DLDatasetDict:='D:/desk/数据集/100.hdict'</l>
<c>*分割数据集的百分比。</c>
<c>*训练集</c>
<l>TrainingPercent := 80</l>
<c>*验证集</c>
<l>ValidationPercent := 20 </l>
<c>*模型类型</c>
<l>ModelType :='segmentation'</l>
<c>*为了获得可复制的分割，我们设置了一个随机种子。</c>
<c>*这意味着重新运行脚本将导致DLDataset的相同拆分。</c>
<l>SeedRand := 42</l>
<c></c>
<l>model_pretreatment (SeedRand, DLDatasetDict, ImageDir, SegmentationDir, TrainingPercent, ValidationPercent, ExampleDataDir, ModelType, InputImageWidth, InputImageHeight, InputImageDepth, DataDirectoryBaseName, PreprocessParamFileBaseName, DLPreprocessParam, ClassNames, ClassIDs)</l>
<c></c>
<c></c>
<c></c>
<c>***************************训练数据集</c>
<c></c>
<c>*数据集目录，用于由preprocess_dl_dataset编写的任何输出。</c>
<l>DataDirectory := DataDirectoryBaseName + '_' + InputImageWidth + 'x' + InputImageHeight</l>
<c>*预处理后的文件路径</c>
<l>DLDatasetFileName := DataDirectory+'/dl_dataset.hdict'</l>
<c>*预处理的参数文件路径</c>
<l>DLPreprocessParamFileName := DataDirectory + '/fissure_Preprocessing_parameters.hdict'</l>
<c>*最佳评估模型的输出路径。</c>
<l>BestModelBaseName := ExampleDataDir + '/best_dl_model_classification.hdl'</l>
<c>*最终训练模型的输出路径。</c>
<l>FinalModelBaseName := ExampleDataDir + '/final_dl_model_classification'</l>
<c>*读入在预处理过程中初始化的模型。也就是读取神经网络模型</c>
<l>Filename:='D:/desk/数据集/UNet_3.hdl'</l>
<c></c>
<c></c>
<c>********************************************超参数设置</c>
<c>* Batch size.</c>
<l>BatchSize := 8</l>
<c>*学习率</c>
<l>InitialLearningRate := 0.002</l>
<c>*如果批量小，动量应高。</c>
<l>Momentum := 0.99</l>
<c>*训练模型的时迭代次数。</c>
<l>NumEpochs := 6</l>
<c>*评估间隔（以时期计），以计算验证拆分上的评估度量。每迭代一次验证一次</c>
<l>EvaluationIntervalEpochs := 1</l>
<c>*如果不应该改变学习率，则将其设置为[]。</c>
<l>ChangeLearningRateEpochs := [3,6,8]</l>
<l>ChangeLearningRateValues := InitialLearningRate * [0.1,0.01,0.001]</l>
<c>*事先设定权重。</c>
<l>WeightPrior := 0.00001</l>
<c>*控制是否显示训练进度（是/否）。</c>
<l>DisplayEvaluation := true</l>
<c>*设置一个随机的种子进行训练。</c>
<l>RandomSeed := 42</l>
<l>train_model (ChangeLearningRateEpochs, InitialLearningRate, ChangeLearningRateValues, BestModelBaseName, FinalModelBaseName, ExampleDataDir, DLPreprocessParamFileName, DLDatasetFileName, Filename, Momentum, InputImageWidth, InputImageHeight, InputImageDepth, BatchSize, WeightPrior, NumEpochs, EvaluationIntervalEpochs, DisplayEvaluation, RandomSeed, DLPreprocessParam, ClassNames, ClassIDs, DLDataset, DLModelHandle)</l>
<l>NumDisplay:=10</l>
<l>Evaluation_Model (DLDataset, DLModelHandle, NumDisplay)</l>
<c></c>
<c></c>
<c>* </c>
<c>* </c>
<c>* Batch Size used during inference.</c>
<l>BatchSizeInference := 11 </l>
<c>* </c>
<c>* ********************</c>
<c>* **   Inference   ***</c>
<c>* ********************</c>
<c>* </c>
<c>* Check if all necessary files exist.</c>
<l>create_dict (WindowDict)</l>
<l>get_dl_model_param (DLModelHandle, 'class_ids', ClassIds)</l>
<l>get_dl_model_param (DLModelHandle, 'class_names', ClassNames)</l>
<l>create_dict (DLDatasetInfo)</l>
<l>set_dict_tuple (DLDatasetInfo, 'class_ids', ClassIds)</l>
<l>set_dict_tuple (DLDatasetInfo, 'class_names', ClassNames)</l>
<l as_id="image_acquisition" as_name="Image Acquisition 01" as_grp="[1,2]" as_ord="1">ImageFiles := []</l>
<l>ImageFiles[0] := 'D:/desk/数据集/liefeng/1 (1).jpg'</l>
<l>ImageFiles[1] := 'D:/desk/数据集/liefeng/1 (2).jpg'</l>
<l>ImageFiles[2] := 'D:/desk/数据集/liefeng/1 (4).jpg'</l>
<l>ImageFiles[3] := 'D:/desk/数据集/liefeng/1 (5).jpg'</l>
<l>ImageFiles[4] := 'D:/desk/数据集/liefeng/1 (6).jpg'</l>
<l>ImageFiles[5] := 'D:/desk/数据集/liefeng/1 (7).jpg'</l>
<l>ImageFiles[6] := 'D:/desk/数据集/liefeng/1 (8).jpg'</l>
<c>*****************************************</c>
<c>*按照上述设置指定模型超参数。</c>
<l>set_dl_model_param (DLModelHandle, 'learning_rate', InitialLearningRate)</l>
<l>set_dl_model_param (DLModelHandle, 'momentum', Momentum)</l>
<c>*设置模型的类名。</c>
<l>get_dict_tuple (DLDataset, 'class_names', ClassNames)</l>
<l as_id="image_acquisition" as_name="Image Acquisition 01" as_grp="[2,2]" as_ord="1">for Index := 0 to |ImageFiles| - 1 by 1</l>
<l as_id="image_acquisition" as_name="Image Acquisition 01" as_grp="[2,3]" as_ord="1">    read_image (Image, 'D:/desk/数据集/liefeng/5.png')</l>
<l>    gen_dl_samples_from_images (Image, DLSample)</l>
<l>    preprocess_dl_samples (DLSample, DLPreprocessParam)</l>
<l>    apply_dl_model (DLModelHandle,DLSample, ['segmentation_image', 'segmentation_confidence'], DLResult)</l>
<l>    get_dict_object (SegmentationImage, DLResult, 'segmentation_image')</l>
<l>    threshold (SegmentationImage, ClassRegions, ClassIDs, ClassIDs)</l>
<l>    dev_display_dl_data (DLSample, DLResult, DLDatasetInfo, ['segmentation_image_result', 'segmentation_confidence_map'], [], WindowDict)</l>
<l>    stop ()</l>
<l as_id="image_acquisition" as_name="Image Acquisition 02" as_grp="[3,1]" as_ord="1">endfor</l>
<c></c>
<l>dev_close_window_dict (WindowDict)</l>
<c></c>
<c></c>
</body>
<docu id="main">
<parameters/>
</docu>
</procedure>
<procedure name="create_unet_model">
<interface>
<ic>
<par name="InputImageHeight" base_type="ctrl" dimension="0"/>
<par name="InputImageWidth" base_type="ctrl" dimension="0"/>
<par name="InputImageDepth" base_type="ctrl" dimension="0"/>
<par name="hdl_name" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* </c>
<c>* 创建输入层.</c>
<l>create_dl_layer_input ('segmentation_image_target', [InputImageWidth,InputImageHeight,1], [], [], DLLayerImageTarget)</l>
<l>create_dl_layer_class_id_conversion (DLLayerImageTarget, 'target', 'from_class_id', [], [], DLLayerTarget)</l>
<l>create_dl_layer_input ('image', [InputImageWidth,InputImageHeight,InputImageDepth], [], [], DLLayerInput)</l>
<l>create_dl_layer_input ('weight_image', [InputImageWidth,InputImageHeight,1], [], [], DLLayerWeights)</l>
<c>* </c>
<c>* 创建网络的核心.</c>
<c>***************</c>
<c>***第一层输入***</c>
<c>***************</c>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerInput, 'convolution_input_11',\
                             3, 1, 1,64, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_11)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_input_11, 'convolution_input_12',\
                             3, 1, 1,64, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_12)</l>
<c>*第一个池化层</c>
<l>create_dl_layer_pooling (DLLayerConvolution_input_12, 'pooling1',\
                         [2,2], [2,2], 'none', 'maximum', [], [], DLLayerPooling1)</l>
<c></c>
<c>***************</c>
<c>***第二层输入***</c>
<c>***************</c>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerPooling1, 'convolution_input_21',\
                             3, 1, 1,128, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_21)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_input_21, 'convolution_input_22',\
                             3, 1, 1,128, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_22)</l>
<c></c>
<c>*第二个池化层</c>
<l>create_dl_layer_pooling (DLLayerConvolution_input_22, 'pooling2',\
                         [2,2], [2,2], 'none', 'maximum', [], [], DLLayerPooling2)</l>
<c></c>
<c>***************</c>
<c>***第三层输入***</c>
<c>***************</c>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerPooling2, 'convolution_input_31',\
                             3, 1, 1,256, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_31)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_input_31, 'convolution_input_32',\
                             3, 1, 1,256, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_32)</l>
<c></c>
<c>*第三个池化层</c>
<l>create_dl_layer_pooling (DLLayerConvolution_input_32, 'pooling3',\
                         [2,2], [2,2], 'none', 'maximum', [], [], DLLayerPooling3)</l>
<c>***************</c>
<c>***第四层输入***</c>
<c>***************</c>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerPooling3, 'convolution_input_41',\
                             3, 1, 1,512, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_41)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_input_41, 'convolution_input_42',\
                             3, 1, 1,512, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_42)</l>
<c></c>
<c>*第四个池化层</c>
<l>create_dl_layer_pooling (DLLayerConvolution_input_42, 'pooling4',\
                         [2,2], [2,2], 'none', 'maximum', [], [], DLLayerPooling4)</l>
<c></c>
<c>***************</c>
<c>***第五层输入***</c>
<c>***************</c>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerPooling4, 'convolution_input_51',\
                             3, 1, 1,1024, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_51)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_input_51, 'convolution_input_52',\
                             3, 1, 1,1024, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_input_52)</l>
<c></c>
<c>*第四个反卷积层</c>
<l>create_dl_layer_transposed_convolution (DLLayerConvolution_input_52,'transposed_convolution4',\
                                        2, 2, 512, 1, 'none', \
                                        [], [], DLLayerTransposedConvolution4)</l>
<c></c>
<c></c>
<c>***************</c>
<c>***第四层输出***</c>
<c>***************</c>
<c>*第四次特征尺寸缩放</c>
<l>create_dl_layer_zoom_size (DLLayerConvolution_input_42, 'zoom_size4', \
                           12, 12, 'bilinear', 'false', [], [], DLLayerZoom4)</l>
<c>*第四个连接层</c>
<l>create_dl_layer_concat ([DLLayerZoom4,DLLayerTransposedConvolution4],\
                        'concat4', 'depth', [], [], DLLayerConcat4)</l>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConcat4, 'convolution_output_41',\
                             3, 1, 1,512, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_41)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_output_41, 'convolution_output_42',\
                             3, 1, 1,512, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_42)</l>
<c>*第三个反卷积层</c>
<l>create_dl_layer_transposed_convolution (DLLayerConvolution_output_42,'transposed_convolution3',\
                                        2, 2, 256, 1, 'none', \
                                        [], [], DLLayerTransposedConvolution3)</l>
<c></c>
<c>***************</c>
<c>***第三层输出***</c>
<c>***************</c>
<c></c>
<c>*第三次特征尺寸缩放</c>
<l>create_dl_layer_zoom_size (DLLayerConvolution_input_32, 'zoom_size3', \
                           16, 16, 'bilinear', 'false', [], [], DLLayerZoom3)</l>
<c>*第三个连接层</c>
<l>create_dl_layer_concat ([DLLayerZoom3,DLLayerTransposedConvolution3],\
                        'concat3', 'depth', [], [], DLLayerConcat3)</l>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConcat3, 'convolution_output_31',\
                             3, 1, 1,256, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_31)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_output_31, 'convolution_output_32',\
                             3, 1, 1,256, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_32)</l>
<c>*第二个反卷积层</c>
<l>create_dl_layer_transposed_convolution (DLLayerConvolution_output_32,'transposed_convolution2',\
                                        2, 2, 128, 1, 'none', \
                                        [], [], DLLayerTransposedConvolution2)</l>
<c>***************</c>
<c>***第二层输出***</c>
<c>***************</c>
<c>*第二次特征尺寸缩放</c>
<l>create_dl_layer_zoom_size (DLLayerConvolution_input_22, 'zoom_size2', \
                           24, 24, 'bilinear', 'false', [], [], DLLayerZoom2)</l>
<c></c>
<c>*第二个连接层</c>
<l>create_dl_layer_concat ([DLLayerZoom2,DLLayerTransposedConvolution2],\
                        'concat2', 'depth', [], [], DLLayerConcat2)</l>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConcat2, 'convolution_output_21',\
                             3, 1, 1,128, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_21)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_output_21, 'convolution_output_22',\
                             3, 1, 1,128, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_22)</l>
<c>*第一个反卷积层</c>
<l>create_dl_layer_transposed_convolution (DLLayerConvolution_output_22,'transposed_convolution1',\
                                        2, 2, 64, 1, 'none', \
                                        [], [], DLLayerTransposedConvolution1)</l>
<c></c>
<c>***************</c>
<c>***第一层输出***</c>
<c>***************</c>
<c>*第一次特征尺寸缩放</c>
<l>create_dl_layer_zoom_size (DLLayerConvolution_input_12, 'zoom_size1', \
                           40, 40, 'bilinear', 'false', [], [], DLLayerZoom1)</l>
<c>*第一个连接层</c>
<l>create_dl_layer_concat ([DLLayerZoom1,DLLayerTransposedConvolution1],\
                        'concat1', 'depth', [], [], DLLayerConcat1)</l>
<c>*第一个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConcat1, 'convolution_output_11',\
                             3, 1, 1,64, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_11)</l>
<c></c>
<c>*第二个卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_output_11, 'convolution_output_12',\
                             3, 1, 1,64, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_12)</l>
<c></c>
<c>*1x1卷积层</c>
<l>create_dl_layer_convolution (DLLayerConvolution_output_12, 'convolution_output_13',\
                             1, 1, 1,3, 1, 'none', 'relu',\
                             'bias_filler_variance_norm', 'norm_out', DLLayerConvolution_output_13)</l>
<c></c>
<l>create_dl_layer_zoom_to_layer_size (DLLayerConvolution_output_13, DLLayerTarget, 'zoom', 'bilinear', 'false', [], [], DLLayerZoom)</l>
<c>* </c>
<c></c>
<c></c>
<c>* Add a softmax and a loss layer to enable training.</c>
<l>create_dl_layer_softmax (DLLayerZoom, 'softmax', [], [], DLLayerSoftMax)</l>
<l>create_dl_layer_loss_cross_entropy (DLLayerSoftMax, DLLayerTarget, DLLayerWeights, 'loss_cross_entropy', 1, [], [], DLLayerLossCrossEntropy)</l>
<c>* </c>
<c>* Create a segmentation image with class ids.</c>
<l>create_dl_layer_depth_max (DLLayerSoftMax, 'segmentation_image_softmax', 'argmax', [], [], DLLayerSegmentationSoftMax, _)</l>
<l>create_dl_layer_class_id_conversion (DLLayerSegmentationSoftMax, 'segmentation_image', 'to_class_id', [], [], DLLayerSegmentationImage)</l>
<c>* </c>
<c>* Create a segmentation confidence image.</c>
<l>create_dl_layer_depth_max (DLLayerSoftMax, 'segmentation_confidence', 'value', [], [], _, DLLayerSegmentationConfidence)</l>
<c>* </c>
<c>* Create the model by passing over a list of output layers.</c>
<c>* The created model then contains all layers that directly</c>
<c>* or indirectly feed into these output layers.</c>
<l>create_dl_model ([DLLayerLossCrossEntropy,DLLayerSegmentationImage,DLLayerSegmentationConfidence], DLModelHandle)</l>
<c></c>
<l>set_dl_model_param (DLModelHandle, 'type', 'segmentation')</l>
<c></c>
<l>write_dl_model (DLModelHandle, hdl_name)</l>
</body>
<docu id="create_unet_model">
<parameters>
<parameter id="InputImageDepth"/>
<parameter id="InputImageHeight"/>
<parameter id="InputImageWidth"/>
<parameter id="hdl_name"/>
</parameters>
</docu>
</procedure>
<procedure name="model_pretreatment">
<interface>
<ic>
<par name="SeedRand" base_type="ctrl" dimension="0"/>
<par name="DLDatasetDict" base_type="ctrl" dimension="0"/>
<par name="ImageDir" base_type="ctrl" dimension="0"/>
<par name="SegmentationDir" base_type="ctrl" dimension="0"/>
<par name="TrainingPercent" base_type="ctrl" dimension="0"/>
<par name="ValidationPercent" base_type="ctrl" dimension="0"/>
<par name="ExampleDataDir" base_type="ctrl" dimension="0"/>
<par name="ModelType" base_type="ctrl" dimension="0"/>
<par name="InputImageWidth" base_type="ctrl" dimension="0"/>
<par name="InputImageHeight" base_type="ctrl" dimension="0"/>
<par name="InputImageDepth" base_type="ctrl" dimension="0"/>
<par name="DataDirectoryBaseName" base_type="ctrl" dimension="0"/>
</ic>
<oc>
<par name="PreprocessParamFileBaseName" base_type="ctrl" dimension="0"/>
<par name="DLPreprocessParam" base_type="ctrl" dimension="0"/>
<par name="ClassNames" base_type="ctrl" dimension="0"/>
<par name="ClassIDs" base_type="ctrl" dimension="0"/>
</oc>
</interface>
<body>
<c>*类名</c>
<l>ClassNames:=['background','crack']</l>
<c>*类id</c>
<l>ClassIDs:=[0,1]</l>
<c>*用于图像预处理的其他参数。</c>
<l>NormalizationType := 'none'</l>
<l>DomainHandling := 'full_domain'</l>
<c></c>
<c></c>
<c>*设置随机种子。</c>
<l>set_system ('seed_rand', SeedRand)</l>
<c>*使用过程read_dl_dataset_segmentation读取数据集。</c>
<c>*或者，您可以使用read_dict（）读取由MVTec深度学习工具创建的DLDataset字典。</c>
<l>* read_dict (DLDatasetDict, [], [], DLDataset)</l>
<l> read_dl_dataset_segmentation (ImageDir, SegmentationDir, ClassNames, ClassIDs, [], [], [], DLDataset)</l>
<c>*分割数据集</c>
<l>split_dl_dataset (DLDataset, TrainingPercent, ValidationPercent, [])</l>
<c>*创建输出目录（如果尚不存在）。</c>
<l>file_exists (ExampleDataDir, FileExists)</l>
<l>if (not FileExists)</l>
<l>    make_dir (ExampleDataDir)</l>
<l>endif</l>
<c>*创建预处理参数。</c>
<c></c>
<l>create_dl_preprocess_param ('segmentation', InputImageWidth, InputImageHeight, InputImageDepth, -127, 128, NormalizationType, DomainHandling, [], [], [], [], DLPreprocessParam)</l>
<c>* </c>
<c>*数据集目录，用于由preprocess_dl_dataset编写的任何输出。</c>
<l>DataDirectory := DataDirectoryBaseName + '_' + InputImageWidth + 'x' + InputImageHeight</l>
<c>* </c>
<c>*预处理数据集。 这可能需要几秒钟。</c>
<l>create_dict (GenParam)</l>
<l>set_dict_tuple (GenParam, 'overwrite_files', true)</l>
<l>set_dict_tuple (GenParam, 'show_progress', true)</l>
<c></c>
<c></c>
<c></c>
<c>*对DLDataset中声明的整个数据集进行标准预处理</c>
<l>preprocess_dl_dataset (DLDataset, DataDirectory, DLPreprocessParam, GenParam, DLDatasetFileName)</l>
<c>* </c>
<c>*单独存储预处理参数以便使用，未标准预处理</c>
<l>PreprocessParamFileBaseName := DataDirectory + '/fissure_Preprocessing_parameters.hdict'</l>
<l>write_dict (DLPreprocessParam, PreprocessParamFileBaseName, [], [])</l>
<l>return ()</l>
</body>
<docu id="model_pretreatment">
<parameters>
<parameter id="ClassIDs"/>
<parameter id="ClassNames"/>
<parameter id="DLDatasetDict"/>
<parameter id="DLPreprocessParam"/>
<parameter id="DataDirectoryBaseName"/>
<parameter id="ExampleDataDir"/>
<parameter id="ImageDir"/>
<parameter id="InputImageDepth"/>
<parameter id="InputImageHeight"/>
<parameter id="InputImageWidth"/>
<parameter id="ModelType"/>
<parameter id="PreprocessParamFileBaseName"/>
<parameter id="SeedRand"/>
<parameter id="SegmentationDir"/>
<parameter id="TrainingPercent"/>
<parameter id="ValidationPercent"/>
</parameters>
</docu>
</procedure>
<procedure name="train_model">
<interface>
<ic>
<par name="ChangeLearningRateEpochs" base_type="ctrl" dimension="0"/>
<par name="InitialLearningRate" base_type="ctrl" dimension="0"/>
<par name="ChangeLearningRateValues" base_type="ctrl" dimension="0"/>
<par name="BestModelBaseName" base_type="ctrl" dimension="0"/>
<par name="FinalModelBaseName" base_type="ctrl" dimension="0"/>
<par name="ExampleDataDir" base_type="ctrl" dimension="0"/>
<par name="DLPreprocessParamFileName" base_type="ctrl" dimension="0"/>
<par name="DLDatasetFileName" base_type="ctrl" dimension="0"/>
<par name="Filename" base_type="ctrl" dimension="0"/>
<par name="Momentum" base_type="ctrl" dimension="0"/>
<par name="InputImageWidth" base_type="ctrl" dimension="0"/>
<par name="InputImageHeight" base_type="ctrl" dimension="0"/>
<par name="InputImageDepth" base_type="ctrl" dimension="0"/>
<par name="BatchSize" base_type="ctrl" dimension="0"/>
<par name="WeightPrior" base_type="ctrl" dimension="0"/>
<par name="NumEpochs" base_type="ctrl" dimension="0"/>
<par name="EvaluationIntervalEpochs" base_type="ctrl" dimension="0"/>
<par name="DisplayEvaluation" base_type="ctrl" dimension="0"/>
<par name="RandomSeed" base_type="ctrl" dimension="0"/>
<par name="DLPreprocessParam" base_type="ctrl" dimension="0"/>
<par name="ClassNames" base_type="ctrl" dimension="0"/>
<par name="ClassIDs" base_type="ctrl" dimension="0"/>
</ic>
<oc>
<par name="DLDataset" base_type="ctrl" dimension="0"/>
<par name="DLModelHandle" base_type="ctrl" dimension="0"/>
</oc>
</interface>
<body>
<l>GenParamName := []</l>
<l>GenParamValue := []</l>
<c></c>
<c></c>
<c></c>
<c>*设置增强百分比和方法。</c>
<l>create_dict (AugmentationParam)</l>
<c>*要增加的样本百分比。</c>
<l>set_dict_tuple (AugmentationParam, 'augmentation_percentage', 20)</l>
<c>*沿行和列镜像。</c>
<l>set_dict_tuple (AugmentationParam, 'mirror', 'rc')</l>
<l>GenParamName := [GenParamName,'augment']</l>
<l>GenParamValue := [GenParamValue,AugmentationParam]</l>
<c>*在训练过程中可以更改模型参数。</c>
<c>*更改学习率。</c>
<l>if (|ChangeLearningRateEpochs| &gt; 0)</l>
<l>    create_dict (ChangeStrategy)</l>
<c>    * 指定要更改的模型参数，这里是学习率。</c>
<l>    set_dict_tuple (ChangeStrategy, 'model_param', 'learning_rate')</l>
<c>    * 从` initial_value `开始设置参数值。</c>
<l>    set_dict_tuple (ChangeStrategy, 'initial_value', InitialLearningRate)</l>
<c>    * 在接下来的几次减少学习率。</c>
<l>    set_dict_tuple (ChangeStrategy, 'epochs', ChangeLearningRateEpochs)</l>
<c>    * 将学习率降低到以下值。</c>
<l>    set_dict_tuple (ChangeStrategy, 'values', ChangeLearningRateValues)</l>
<c>    * 收集所有的变更策略作为输入。</c>
<l>    GenParamName := [GenParamName,'change']</l>
<l>    GenParamValue := [GenParamValue,ChangeStrategy]</l>
<l>endif</l>
<c></c>
<c></c>
<c></c>
<c>*最佳模型和最终模型保存到设置的路径中</c>
<l>create_dict (SerializationStrategy)</l>
<l>set_dict_tuple (SerializationStrategy, 'type', 'best')</l>
<l>set_dict_tuple (SerializationStrategy, 'basename', BestModelBaseName)</l>
<l>GenParamName := [GenParamName,'serialize']</l>
<l>GenParamValue := [GenParamValue,SerializationStrategy]</l>
<l>create_dict (SerializationStrategy)</l>
<l>set_dict_tuple (SerializationStrategy, 'type', 'final')</l>
<l>set_dict_tuple (SerializationStrategy, 'basename', FinalModelBaseName)</l>
<l>GenParamName := [GenParamName,'serialize']</l>
<l>GenParamValue := [GenParamValue,SerializationStrategy]</l>
<c></c>
<c></c>
<c></c>
<c>*在此示例中，选择了20％的训练分组以显示</c>
<c>*评估在训练过程中减少训练次数的评估措施。 较低的百分比</c>
<c>*有助于加快评估/培训。 如果评估措施用于培训分裂</c>
<c>*不会显示，将此值设置为0（默认值）。</c>
<l>SelectedPercentageTrainSamples := 20</l>
<l>create_dict (DisplayParam)</l>
<l>set_dict_tuple (DisplayParam, 'selected_percentage_train_samples', SelectedPercentageTrainSamples)</l>
<l>GenParamName := [GenParamName,'display']</l>
<l>GenParamValue := [GenParamValue,DisplayParam]</l>
<c></c>
<c></c>
<c></c>
<c>*检查是否所有必需的文件都存在。</c>
<l>file_exists (ExampleDataDir, PathExists)</l>
<l>if ( not PathExists)</l>
<l>    throw (ExampleDataDir+'相关文件不存在')</l>
<l>endif</l>
<c>*检测预处理参数文件是否存在</c>
<l>file_exists (DLPreprocessParamFileName, FileExists)</l>
<l>if ( not FileExists)</l>
<l>    throw (DLPreprocessParamFileName+'相关文件不存在')</l>
<l>endif</l>
<c>*检测Dataset文件是否存在</c>
<l>file_exists (DLDatasetFileName, FileExists)</l>
<l>if ( not FileExists)</l>
<l>    throw (DLDatasetFileName+'相关文件不存在')</l>
<l>endif</l>
<c></c>
<c></c>
<c></c>
<c>*读入在预处理过程中初始化的模型。也就是读取神经网络模型</c>
<l>read_dl_model ('D:/desk/数据集/UNet_3.hdl', DLModelHandle)</l>
<l>set_dl_model_param_based_on_preprocessing (DLModelHandle, DLPreprocessParam, ClassIDs)</l>
<l>set_dl_model_param (DLModelHandle, 'class_names', ClassNames)</l>
<c></c>
<c>*读取预处理后的图片DLDataset文件。</c>
<l>read_dict (DLDatasetFileName, [], [], DLDataset)</l>
<c>*****************************************得到预处理信息并赋与神经网络模型</c>
<l>get_dict_tuple (DLDataset, 'preprocess_param', DLPreprocessParam)</l>
<l>get_dict_tuple (DLDataset, 'class_ids', ClassIDs)</l>
<l>set_dl_model_param_based_on_preprocessing (DLModelHandle, DLPreprocessParam, ClassIDs)</l>
<c></c>
<c></c>
<c></c>
<c>*****************************************</c>
<c>*按照上述设置指定模型超参数。</c>
<l>set_dl_model_param (DLModelHandle, 'learning_rate', InitialLearningRate)</l>
<l>set_dl_model_param (DLModelHandle, 'momentum', Momentum)</l>
<c>*设置模型的类名。</c>
<l>get_dict_tuple (DLDataset, 'class_names', ClassNames)</l>
<l>set_dl_model_param (DLModelHandle, 'class_names', ClassNames)</l>
<c>*设置输入模型的图片大小和维度</c>
<l>set_dl_model_param (DLModelHandle, 'image_dimensions', [InputImageWidth,InputImageHeight,InputImageDepth])</l>
<c>*设置样本尺寸</c>
<l>if (BatchSize == 'maximum')</l>
<l>    set_dl_model_param_max_gpu_batch_size (DLModelHandle, 100)</l>
<l>else</l>
<l>    set_dl_model_param (DLModelHandle, 'batch_size', BatchSize)</l>
<l>endif</l>
<c>*设置权重</c>
<l>if (|WeightPrior| &gt; 0)</l>
<l>    set_dl_model_param (DLModelHandle, 'weight_prior', WeightPrior)</l>
<l>endif</l>
<l>get_dl_model_param (DLModelHandle, 'batch_size', GenParamValue1)</l>
<c>*优化模型进行推理，</c>
<c>*意思是，减少内存消耗。</c>
<l>set_dl_model_param (DLModelHandle, 'optimize_for_inference', 'true')</l>
<c>*设置GPU内存初始化，提高运行效率，若用CPU训练可忽略</c>
<l>set_dl_model_param (DLModelHandle, 'runtime_init', 'immediately')</l>
<c>*为了避免深度学习工作时的内存问题，增加 "硬盘交换文件 "的大小。</c>
<l>set_system ('cudnn_deterministic', 'true')</l>
<c></c>
<c></c>
<c></c>
<c>*创建训练参数。有超参数的传入GenParamName、GenParamValue</c>
<l>create_dl_train_param (DLModelHandle, NumEpochs, EvaluationIntervalEpochs, \
                       DisplayEvaluation, RandomSeed, GenParamName, GenParamValue, TrainParam)</l>
<c>*开始训练。</c>
<l>train_dl_model (DLDataset, DLModelHandle, TrainParam, 0, TrainResults, TrainInfos, EvaluationInfos)</l>
<l>dev_close_window ()</l>
<l>dev_close_window ()</l>
<l>return ()</l>
</body>
<docu id="train_model">
<parameters>
<parameter id="BatchSize"/>
<parameter id="BestModelBaseName"/>
<parameter id="ChangeLearningRateEpochs"/>
<parameter id="ChangeLearningRateValues"/>
<parameter id="ClassIDs"/>
<parameter id="ClassNames"/>
<parameter id="DLDataset"/>
<parameter id="DLDatasetFileName"/>
<parameter id="DLModelHandle"/>
<parameter id="DLPreprocessParam"/>
<parameter id="DLPreprocessParamFileName"/>
<parameter id="DisplayEvaluation"/>
<parameter id="EvaluationIntervalEpochs"/>
<parameter id="ExampleDataDir"/>
<parameter id="Filename"/>
<parameter id="FinalModelBaseName"/>
<parameter id="InitialLearningRate"/>
<parameter id="InputImageDepth"/>
<parameter id="InputImageHeight"/>
<parameter id="InputImageWidth"/>
<parameter id="Momentum"/>
<parameter id="NumEpochs"/>
<parameter id="RandomSeed"/>
<parameter id="WeightPrior"/>
</parameters>
</docu>
</procedure>
<procedure name="dev_display_continue_message">
<interface>
<ic>
<par name="WindowHandleDict" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* This procedure displays the continue message in the right-most window.</c>
<c></c>
<c>* Get all window handles.</c>
<l>try</l>
<l>    remove_dict_key (WindowHandleDict, 'meta_information')</l>
<l>catch (Exception)</l>
<l>endtry</l>
<l>get_dict_param (WindowHandleDict, 'keys', [], WindowKeys)</l>
<l>WindowHandles := []</l>
<l>for KIdx := 0 to |WindowKeys| - 1 by 1</l>
<l>    get_dict_tuple (WindowHandleDict, WindowKeys[KIdx], WindowHandlesTmp)</l>
<l>    WindowHandles := [WindowHandles,WindowHandlesTmp]</l>
<l>endfor</l>
<c>* Get the total width of the window handles without the last one.</c>
<l>TotalWidth := 0</l>
<l>for WIdx := 0 to |WindowHandles| - 2 by 1</l>
<l>    get_window_extents (WindowHandles[WIdx], Row, Column, Width, Height)</l>
<l>    TotalWidth := TotalWidth + Width</l>
<l>endfor</l>
<c></c>
<l>WindowHandle := WindowHandles[|WindowHandles| - 1]</l>
<l>ContinueText := 'Press Run (F5) to continue'</l>
<l>get_string_extents (WindowHandle, ContinueText, Ascent, Descent, StringWidth, StringHeight)</l>
<c></c>
<l>dev_set_window (WindowHandle)</l>
<l>get_window_extents (WindowHandle, Row, Column, Width, Height)</l>
<l>dev_set_window_extents (0, TotalWidth + 12, max2(Width,StringWidth + 40), Height)</l>
<l>dev_disp_text ('Press Run (F5) to continue', 'window', 'bottom', 'right', 'black', 'box', 'true')</l>
<c></c>
<l>return ()</l>
</body>
<docu id="dev_display_continue_message">
<parameters>
<parameter id="WindowHandleDict"/>
</parameters>
</docu>
</procedure>
<procedure name="Evaluation_Model">
<interface>
<ic>
<par name="DLDataset" base_type="ctrl" dimension="0"/>
<par name="DLModelHandle" base_type="ctrl" dimension="0"/>
<par name="NumDisplay" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<l>create_dict (GenParamEval)</l>
<c>*设置参数</c>
<c>*评价措施。</c>
<c>*</c>
<c>*mean_iou 均交并比 该类的真实标签和预测值的交和并的比值</c>
<c>*class_iou 交并比(IoU) 正确预测像素与注释和预测像素的并集的比率。从视觉上看，这是区域的交集和并集之间的比率</c>
<c>*pixel_accuracy 像素准确率 预测像素的准确率高低 </c>
<c>*class_pixel_accuracy 类别像素准确率 在类别 i 的预测值中，真实属于 i 类的像素准确率</c>
<c>*absolute_confusion_matrix  绝对混淆矩阵</c>
<c>*</c>
<c>*</c>
<c>*</c>
<c>*</c>
<l>SegmentationMeasures := ['class_iou', 'pixel_accuracy', 'class_pixel_accuracy', 'pixel_confusion_matrix']</l>
<l>set_dict_tuple (GenParamEval, 'measures', SegmentationMeasures)</l>
<l>set_dict_tuple (GenParamEval, 'show_progress', 'true')</l>
<c>* 评估训练好的模型.</c>
<l>evaluate_dl_model (DLDataset, DLModelHandle, 'split', 'validation',\
                   GenParamEval, EvaluationResult, EvalParams)</l>
<c>* 显示结果</c>
<l>create_dict (WindowHandleDict)</l>
<l>create_dict (GenParamEvalDisplay)</l>
<l>set_dict_tuple (GenParamEvalDisplay, 'display_mode', ['measures', 'absolute_confusion_matrix'])</l>
<c></c>
<c></c>
<l>dev_display_segmentation_evaluation (EvaluationResult, EvalParams, GenParamEvalDisplay, WindowHandleDict)</l>
<l>stop ()</l>
<l>dev_close_window_dict (WindowHandleDict)</l>
<c></c>
<c>* </c>
<c>* </c>
<c>* **************************************</c>
<c>* **   Visual inspection of images   ***</c>
<c>* **************************************</c>
<c>* </c>
<c></c>
<c>* Evaluate the performance of the model qualitatively</c>
<c>* by visual inspection of images.</c>
<c>* Select test images randomly.</c>
<l>get_dict_tuple (DLDataset, 'samples', DatasetSamples)</l>
<l>find_dl_samples (DatasetSamples, 'split', 'validation', 'match', SampleIndices)</l>
<l>tuple_shuffle (SampleIndices, ShuffledIndices)</l>
<c>* Read the selected samples.</c>
<l>read_dl_samples (DLDataset, ShuffledIndices[0:NumDisplay - 1], DLSampleBatch)</l>
<c>* </c>
<c>* Set parameters for visualization of sample images.</c>
<l>create_dict (WindowHandleDict)</l>
<l>create_dict (GenParamDisplay)</l>
<l>set_dict_tuple (GenParamDisplay, 'segmentation_exclude_class_ids', 0)</l>
<l>set_dict_tuple (GenParamDisplay, 'segmentation_transparency', '80')</l>
<c>* </c>
<c>* Set batch size of the model to 1.</c>
<l>set_dl_model_param (DLModelHandle, 'batch_size', 1)</l>
<c>* </c>
<c>* Apply the retrained model and visualize the results.</c>
<l>for SampleIndex := 0 to NumDisplay - 1 by 1</l>
<c>    * </c>
<c>    * Apply the model.</c>
<l>    apply_dl_model (DLModelHandle, DLSampleBatch[SampleIndex], [], DLResult)</l>
<c>    * </c>
<c>    * Display the result.</c>
<l>    dev_display_dl_data (DLSampleBatch[SampleIndex], DLResult, DLDataset, ['segmentation_image_ground_truth', 'segmentation_image_result'], GenParamDisplay, WindowHandleDict)</l>
<c>    * </c>
<l>    dev_display_continue_message (WindowHandleDict)</l>
<l>    stop ()</l>
<l>endfor</l>
<c>* </c>
<c>* Close the windows.</c>
<l>dev_close_window_dict (WindowHandleDict)</l>
<l>return ()</l>
</body>
<docu id="Evaluation_Model">
<parameters>
<parameter id="DLDataset"/>
<parameter id="DLModelHandle"/>
<parameter id="NumDisplay"/>
</parameters>
</docu>
</procedure>
<procedure name="dev_display_ok_nok_COPY_1">
<interface>
<ic>
<par name="Areas" base_type="ctrl" dimension="0"/>
<par name="WindowHandleImage" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* This procedures displays OK if no defects are segmented and NOK otherwise.</c>
<c></c>
<c>* The first entry of Area corresponds to class 'good'.</c>
<l>if (sum(Areas) - Areas[0] &gt; 0)</l>
<l>    Text := 'NOK'</l>
<l>    BoxColor := 'red'</l>
<l>else</l>
<l>    Text := 'OK'</l>
<l>    BoxColor := 'green'</l>
<l>endif</l>
<l>set_display_font (WindowHandleImage, 24, 'mono', 'true', 'false')</l>
<l>dev_disp_text (Text, 'window', 'top', 'left', 'black', ['box_color', 'shadow'], [BoxColor,'false'])</l>
<l>set_display_font (WindowHandleImage, 16, 'mono', 'true', 'false')</l>
<l>dev_disp_text ('Press Run (F5) to continue', 'window', 'bottom', 'left', 'black', 'box', 'true')</l>
<l>flush_buffer (WindowHandleImage)</l>
<l>return ()</l>
</body>
<docu id="dev_display_ok_nok_COPY_1">
<parameters>
<parameter id="Areas"/>
<parameter id="WindowHandleImage"/>
</parameters>
</docu>
</procedure>
<procedure name="get_inference_images">
<interface>
<ic>
<par name="ImageDir" base_type="ctrl" dimension="0"/>
</ic>
<oc>
<par name="ImageFiles" base_type="ctrl" dimension="0"/>
</oc>
</interface>
<body>
<c>* This procedure selects some images for the demonstration purposes of this example.</c>
<c></c>
<l>ImageFiles := ImageDir + '/ginseng/contamination/pill_ginseng_contamination_154'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/magnesium/crack/pill_magnesium_crack_036'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/mint/good/pill_mint_good_165'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/ginseng/crack/pill_ginseng_crack_004'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/magnesium/good/pill_magnesium_good_066'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/ginseng/contamination/pill_ginseng_contamination_244'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/mint/contamination/pill_mint_contamination_076'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/magnesium/contamination/pill_magnesium_contamination_011'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/ginseng/good/pill_ginseng_good_042'</l>
<l>ImageFiles[|ImageFiles|] := ImageDir + '/mint/crack/pill_mint_crack_121'</l>
<l>return ()</l>
</body>
<docu id="get_inference_images">
<parameters>
<parameter id="ImageDir"/>
<parameter id="ImageFiles"/>
</parameters>
</docu>
</procedure>
<procedure name="dev_display_ok_nok">
<interface>
<ic>
<par name="Areas" base_type="ctrl" dimension="0"/>
<par name="WindowHandleImage" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* This procedures displays OK if no defects are segmented and NOK otherwise.</c>
<c></c>
<c>* The first entry of Area corresponds to class 'good'.</c>
<l>if (sum(Areas) - Areas[0] &gt; 0)</l>
<l>    Text := 'NOK'</l>
<l>    BoxColor := 'red'</l>
<l>else</l>
<l>    Text := 'OK'</l>
<l>    BoxColor := 'green'</l>
<l>endif</l>
<l>set_display_font (WindowHandleImage, 24, 'mono', 'true', 'false')</l>
<l>dev_disp_text (Text, 'window', 'top', 'left', 'black', ['box_color', 'shadow'], [BoxColor,'false'])</l>
<l>set_display_font (WindowHandleImage, 16, 'mono', 'true', 'false')</l>
<l>dev_disp_text ('Press Run (F5) to continue', 'window', 'bottom', 'left', 'black', 'box', 'true')</l>
<l>flush_buffer (WindowHandleImage)</l>
<l>return ()</l>
</body>
<docu id="dev_display_ok_nok">
<parameters>
<parameter id="Areas"/>
<parameter id="WindowHandleImage"/>
</parameters>
</docu>
</procedure>
</hdevelop>
